{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shapes:\n",
      "X_train:  (712, 24)\n",
      "X_val:  (179, 24)\n",
      "X_test:  (418, 24)\n",
      "Missing values in processed data:\n",
      "Training:  0\n",
      "Validation:  0\n",
      "Test:  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.preprocessing import TitanicPreprocessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example usage\n",
    "# Load processed data\n",
    "train = pd.read_csv('../data/processed/train_processed.csv')\n",
    "test = pd.read_csv('../data/processed/test_processed.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = train.drop(['Survived', 'Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "# Drop features for test dataset\n",
    "X_test = test.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and use preprocessor\n",
    "preprocessor = TitanicPreprocessor()\n",
    "\n",
    "# Correct usage: fit_transform on training, transform on validation and test data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Processed shapes:\")\n",
    "print(\"X_train: \", X_train_processed.shape)\n",
    "print(\"X_val: \", X_val_processed.shape)\n",
    "print(\"X_test: \", X_test_processed.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print('Missing values in processed data:')\n",
    "print('Training: ', np.isnan(X_train_processed).sum())\n",
    "print('Validation: ', np.isnan(X_val_processed).sum())\n",
    "print('Test: ', np.isnan(X_val_processed).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\n",
    "np.save('../data/processed/X_train_processed.npy', X_train_processed)\n",
    "np.save('../data/processed/X_val_processed.npy', X_val_processed)\n",
    "np.save('../data/processed/X_test_processed.npy', X_test_processed)\n",
    "np.save('../data/processed/y_train.npy', y_train)\n",
    "np.save('../data/processed/y_val.npy', y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
